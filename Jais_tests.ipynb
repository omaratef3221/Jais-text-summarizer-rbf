{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_rX2AZs4m2H",
    "outputId": "b390fd04-f278-41f0-a24a-45ab9823369e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers --quiet\n",
    "!pip install accelerate --quiet\n",
    "!pip install torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_path = \"inception-mbzuai/jais-13b\"\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Available device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "POfXv3kI4cab"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e6d1f73a77481e8b9f0101428c57e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", trust_remote_code=True, offload_folder=\"offload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LpCgJ1xh97Gs"
   },
   "outputs": [],
   "source": [
    "def get_response(text,tokenizer=tokenizer,model=model):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    inputs = input_ids.to(device)\n",
    "    input_len = inputs.shape[-1]\n",
    "\n",
    "    generate_ids = model.generate(\n",
    "        inputs,\n",
    "        top_p=0.9,\n",
    "        temperature=0.3,\n",
    "        max_length=200-input_len,\n",
    "        min_length=input_len + 4,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    response = tokenizer.batch_decode(\n",
    "        generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtasQbsPEwcB"
   },
   "source": [
    "## Basic Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1rS90KkZ4gnm",
    "outputId": "ecaed4ac-7e3e-4c13-ab4c-35834e1e08d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عاصمة دولة الإمارات العربية المتحدة هيمدينة أبوظبي, وهي أكبر مدينة في البلاد. تقع على جزيرة أبو ظبي وتحيط بها المياه الزرقاء للخليج العربي. المدينة هي موطن للعديد من المعالم السياحية الشهيرة مثل مسجد الشيخ زايد الكبير ومتحف اللوفر وقصر الوطن وغيرها الكثير.\n",
      "Arabic Response inference time:  4.8393  Seconds\n",
      "\n",
      "==============================\n",
      "The capital of UAE is  Abu Dhabi. The population was estimated at 8,634,000 in 2015 and the country's total area is 83,600 km2 (32,100 sq mi).\n",
      "\n",
      "Abu Dhabi has a temperate climate with hot summers from April to October; winters are cool but dry between November and March. Annual rainfall averages around 100 mm (4 inches) per year.\n",
      "\n",
      "The economy of Abu Dhabi depends on oil production which accounts for about 90% of its gross domestic product (GDP), as well as tourism and real estate development. Its main exports include petroleum products such as crude oil, natural gas condensates, liquefied natural gas, refined petroleum products including gasoline, diesel fuel, kerosene, jet fuels, lubricants, and petrochemicals. Other major exports include aluminum, copper, iron ore, fertilizers, steel, cement, and text\n",
      "English Response inference time:  15.5824  Seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# English prediction\n",
    "text= \"عاصمة دولة الإمارات العربية المتحدة ه\"\n",
    "start = time.time()\n",
    "arabic_response = get_response(text)\n",
    "print(arabic_response)\n",
    "print(\"Arabic Response inference time: \", round(time.time()-start,4), \" Seconds\\n\")\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Arabic prediction\n",
    "start = time.time()\n",
    "text = \"The capital of UAE is \"\n",
    "English_response = get_response(text)\n",
    "print(English_response)\n",
    "print(\"English Response inference time: \", round(time.time()-start,4), \" Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbf_layer import RBFLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pwXq6jKMahu"
   },
   "source": [
    "## Model Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_XAc8vyNkVP",
    "outputId": "fb05aa72-48f1-4b4f-9771-2d2952637a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable model parameters: 0\n",
      "All model parameters: 13020811960\n",
      "Percentage of trainable model parameters: 0.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"Trainable model parameters: {trainable_model_params}\\nAll model parameters: {all_model_params}\\nPercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKcr6_u9x6bt"
   },
   "source": [
    "# Layer replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRhZEUciWdz7",
    "outputId": "0a8309f9-c856-455f-ec56-6b8775cc9a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_head Linear(in_features=5120, out_features=84992, bias=False)\n",
      "lm_head <bound method Module.parameters of Linear(in_features=5120, out_features=84992, bias=False)>\n"
     ]
    }
   ],
   "source": [
    "for k, m in model.named_modules():\n",
    "  if type(m).__name__ == 'Linear':\n",
    "    print(k,m)\n",
    "    print(k,m.parameters)\n",
    "  else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gQvBQrNuWfOh"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mWWRJXO3y7wr"
   },
   "outputs": [],
   "source": [
    "def l_norm(x, p=2):\n",
    "    return torch.norm(x, p=p, dim=-1)\n",
    "\n",
    "\n",
    "# Gaussian RBF\n",
    "def rbf_gaussian(x):\n",
    "    return (-x.pow(2)).exp()\n",
    "    \n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "      model._modules[name] = RBFLayer(in_features_dim = 5120, \n",
    "                                      out_features_dim = 84992, \n",
    "                                      num_kernels = 5, \n",
    "                                      radial_function=rbf_gaussian,\n",
    "                                     norm_function=l_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqujJ_LLA9tb",
    "outputId": "a57ebb7c-974c-4861-b70e-9800e9489f9e"
   },
   "outputs": [],
   "source": [
    "for k, m in model.named_modules():\n",
    "  if type(m).__name__ == 'Linear':\n",
    "    print(k,m)\n",
    "    print(k,m.parameters)\n",
    "  else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-86mK3Ux33g",
    "outputId": "16f6dd02-dc1d-4160-e88a-e7d2b2f94a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable model parameters: 450565\n",
      "All model parameters: 13021262525\n",
      "Percentage of trainable model parameters: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"updated_layer_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148116f3c2d44092b15a173ad1c30f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at updated_layer_model were not used when initializing JAISLMHeadModel: ['lm_head.weights', 'lm_head.kernels_centers', 'lm_head.log_shapes']\n",
      "- This IS expected if you are initializing JAISLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing JAISLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "new_model = AutoModelForCausalLM.from_pretrained(\"updated_layer_model\", \n",
    "                                                 device_map=\"auto\", \n",
    "                                                 trust_remote_code=True, \n",
    "                                                 offload_folder=\"offload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable model parameters: 0\n",
      "All model parameters: 13020811960\n",
      "Percentage of trainable model parameters: 0.00%\n"
     ]
    }
   ],
   "source": [
    "for param in new_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(new_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(text,tokenizer=tokenizer,model=model):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    inputs = input_ids.to(device)\n",
    "    input_len = inputs.shape[-1]\n",
    "\n",
    "    generate_ids = new_model.generate(\n",
    "        inputs,\n",
    "        top_p=0.9,\n",
    "        temperature=0.3,\n",
    "        max_length=200-input_len,\n",
    "        min_length=input_len + 4,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    response = tokenizer.batch_decode(\n",
    "        generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عاصمة دولة الإمارات العربية المتحدة هوجمت من قبل الإرهابيين.\n",
      "Arabic Response inference time:  3.7902  Seconds\n",
      "\n",
      "==============================\n",
      "The capital of UAE is  Abu Dhabi.\n",
      "\n",
      "History \n",
      "\n",
      "Abu Dhabi was founded in the 18th century by Al-Nahyan tribe, a branch of Bani Yas tribe which originated from Oman and settled on the coasts of what would become known as United Arab Emirates (UAE). The city's name derives from its location at the foot of Mount Dhafra, meaning \"the abode\". In 1761, Sheikh Zayed bin Khalifa Al Nahyan established his residence here after he moved away from Dubai to escape an attack by pirates who had been harassing him for years. He then began to build up the town with the help of other members of the ruling family. By 1820, it became one of the most important ports in the region due to its strategic position between India and Africa; this attracted traders from all over the world including Britain, France, Germany, Portugal\n",
      "English Response inference time:  101.2503  Seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# English prediction\n",
    "text= \"عاصمة دولة الإمارات العربية المتحدة ه\"\n",
    "start = time.time()\n",
    "arabic_response = get_response(text)\n",
    "print(arabic_response)\n",
    "print(\"Arabic Response inference time: \", round(time.time()-start,4), \" Seconds\\n\")\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Arabic prediction\n",
    "start = time.time()\n",
    "text = \"The capital of UAE is \"\n",
    "English_response = get_response(text)\n",
    "print(English_response)\n",
    "print(\"English Response inference time: \", round(time.time()-start,4), \" Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zjm7XgOxOJw"
   },
   "source": [
    "# Complete Methodolgy\n",
    "\n",
    "\n",
    "\n",
    "1.   Read Model\n",
    "2.   Freeze All layers\n",
    "3.   Put my Layer (RBF)\n",
    "4.   Fine tune only that layer on summarization\n",
    "5.   Fine tune the original\n",
    "6.   Compare accuracy (ROUGE) and training time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50xi2nR0YfrV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
