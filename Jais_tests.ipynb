{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_rX2AZs4m2H",
    "outputId": "b390fd04-f278-41f0-a24a-45ab9823369e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers --quiet\n",
    "!pip install accelerate --quiet\n",
    "!pip install torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_path = \"inception-mbzuai/jais-13b\"\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Available device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "POfXv3kI4cab"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6068dbba56498ca2f9df222c8da524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", trust_remote_code=True, offload_folder=\"offload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LpCgJ1xh97Gs"
   },
   "outputs": [],
   "source": [
    "def get_response(text,tokenizer=tokenizer,model=model):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    inputs = input_ids.to(device)\n",
    "    input_len = inputs.shape[-1]\n",
    "\n",
    "    generate_ids = model.generate(\n",
    "        inputs,\n",
    "        top_p=0.9,\n",
    "        temperature=0.3,\n",
    "        max_length=200-input_len,\n",
    "        min_length=input_len + 4,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    response = tokenizer.batch_decode(\n",
    "        generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtasQbsPEwcB"
   },
   "source": [
    "## Basic Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1rS90KkZ4gnm",
    "outputId": "ecaed4ac-7e3e-4c13-ab4c-35834e1e08d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عاصمة دولة الإمارات العربية المتحدة هية مدينة أبو ظبي, وهي أكبر مدن الدولة من حيث المساحة وعدد السكان. تقع على جزيرة أبوظبي التي تحوي مقر رئاسة الدولة ورئاسة مجلس الوزراء والسفارات المعتمدة لدى دولة الإمارات. كما أنها عاصمة المنطقة الشرقية لإمارة أبوظبي والتي تشمل مدنا مثل العين والمنطقة الغربية (ليوا) وجزيرة دلما وجزر القرم الشرقي.\n",
      "Arabic Response inference time:  5.4609  Seconds\n",
      "\n",
      "==============================\n",
      "The capital of UAE is  Abu Dhabi.\n",
      "Abu Dhabi has a population of 1,738,000 (2016).\n",
      "It was the largest city in the United Arab Emirates and its most populous metropolitan area until Dubai surpassed it on 31 December 2008 with 2,912,869 residents according to the latest census data from 2005. The two cities are now tied at 3 million each as per the 2010 Census results released by Statistics Centre Abu Dhabi.\n",
      "\n",
      "Dubai's rapid growth over recent years means that it is expected to overtake Abu Dhabi again soon; however, this will not happen for several decades due to the fact that the majority of people living within the emirate live outside the urban areas.\n",
      "\n",
      "History \n",
      "\n",
      "The first inhabitants were nomads who lived along the coastline or inland around oases where they grew date palms. In 1761, Al Qas\n",
      "English Response inference time:  15.5897  Seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# English prediction\n",
    "text= \"عاصمة دولة الإمارات العربية المتحدة ه\"\n",
    "start = time.time()\n",
    "arabic_response = get_response(text)\n",
    "print(arabic_response)\n",
    "print(\"Arabic Response inference time: \", round(time.time()-start,4), \" Seconds\\n\")\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Arabic prediction\n",
    "start = time.time()\n",
    "text = \"The capital of UAE is \"\n",
    "English_response = get_response(text)\n",
    "print(English_response)\n",
    "print(\"English Response inference time: \", round(time.time()-start,4), \" Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pwXq6jKMahu"
   },
   "source": [
    "## Model Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_XAc8vyNkVP",
    "outputId": "fb05aa72-48f1-4b4f-9771-2d2952637a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable model parameters: 13020811960\n",
      "All model parameters: 13020811960\n",
      "Percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"Trainable model parameters: {trainable_model_params}\\nAll model parameters: {all_model_params}\\nPercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKcr6_u9x6bt"
   },
   "source": [
    "# Layer replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRhZEUciWdz7",
    "outputId": "0a8309f9-c856-455f-ec56-6b8775cc9a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_head Linear(in_features=5120, out_features=84992, bias=False)\n",
      "lm_head <bound method Module.parameters of Linear(in_features=5120, out_features=84992, bias=False)>\n"
     ]
    }
   ],
   "source": [
    "for k, m in model.named_modules():\n",
    "  if type(m).__name__ == 'Linear':\n",
    "    print(k,m)\n",
    "    print(k,m.parameters)\n",
    "  else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gQvBQrNuWfOh"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mWWRJXO3y7wr"
   },
   "outputs": [],
   "source": [
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, torch.nn.Linear):\n",
    "      model._modules[name] = torch.nn.Linear(5120, 84992, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqujJ_LLA9tb",
    "outputId": "a57ebb7c-974c-4861-b70e-9800e9489f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_head Linear(in_features=5120, out_features=84992, bias=False)\n",
      "lm_head <bound method Module.parameters of Linear(in_features=5120, out_features=84992, bias=False)>\n"
     ]
    }
   ],
   "source": [
    "for k, m in model.named_modules():\n",
    "  if type(m).__name__ == 'Linear':\n",
    "    print(k,m)\n",
    "    print(k,m.parameters)\n",
    "  else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-86mK3Ux33g",
    "outputId": "16f6dd02-dc1d-4160-e88a-e7d2b2f94a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable model parameters: 435159040\n",
      "All model parameters: 13455971000\n",
      "Percentage of trainable model parameters: 3.23%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"updated_layer_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56582e0429f4aa1be678adf8b299413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "new_model = AutoModelForCausalLM.from_pretrained(\"updated_layer_model\", \n",
    "                                                 device_map=\"auto\", \n",
    "                                                 trust_remote_code=True, \n",
    "                                                 offload_folder=\"offload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(text,tokenizer=tokenizer,model=model):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    inputs = input_ids.to(device)\n",
    "    input_len = inputs.shape[-1]\n",
    "\n",
    "    generate_ids = new_model.generate(\n",
    "        inputs,\n",
    "        top_p=0.9,\n",
    "        temperature=0.3,\n",
    "        max_length=200-input_len,\n",
    "        min_length=input_len + 4,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    response = tokenizer.batch_decode(\n",
    "        generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عاصمة دولة الإمارات العربية المتحدة ه هي أبو ظبي.\n",
      "Arabic Response inference time:  2.7155  Seconds\n",
      "\n",
      "==============================\n",
      "The capital of UAE is  Abu Dhabi, which has a population of 1.5 million people and the second largest city in the country after Dubai with 2.2 million residents (the total number of Emirati citizens living in both cities was estimated at around 3.3 million).\n",
      "\n",
      "Abu Dhabi's economy relies heavily on oil exports; however, it also features an extensive free trade zone that allows for foreign companies to operate without having to pay taxes or import duties until they export their goods from the region. The government plans to diversify its economy away from petroleum by investing more than $200 billion over the next five years into various industries such as tourism, real estate development, finance, aerospace manufacturing, and telecommunications. In addition, the emirate hosts several international conferences each year including the Formula One Grand Prix held annually since 2009, the World Environment Day Conference, and the International Petroleum Week conference.\n",
      "\n",
      "Dub\n",
      "English Response inference time:  98.0873  Seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# English prediction\n",
    "text= \"عاصمة دولة الإمارات العربية المتحدة ه\"\n",
    "start = time.time()\n",
    "arabic_response = get_response(text)\n",
    "print(arabic_response)\n",
    "print(\"Arabic Response inference time: \", round(time.time()-start,4), \" Seconds\\n\")\n",
    "\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Arabic prediction\n",
    "start = time.time()\n",
    "text = \"The capital of UAE is \"\n",
    "English_response = get_response(text)\n",
    "print(English_response)\n",
    "print(\"English Response inference time: \", round(time.time()-start,4), \" Seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zjm7XgOxOJw"
   },
   "source": [
    "# Complete Methodolgy\n",
    "\n",
    "\n",
    "\n",
    "1.   Read Model\n",
    "2.   Freeze All layers\n",
    "3.   Put my Layer (RBF)\n",
    "4.   Fine tune only that layer on summarization\n",
    "5.   Fine tune the original\n",
    "6.   Compare accuracy (ROUGE) and training time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50xi2nR0YfrV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
