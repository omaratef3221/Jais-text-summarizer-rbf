{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb599c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omaratef/miniconda/envs/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/omaratef/miniconda/envs/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JAISLMHeadModel(\n",
       "  (transformer): JAISModel(\n",
       "    (wte): Embedding(84992, 1536)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-17): 18 x JAISBlock(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): JAISAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): JAISMLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_fc2): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): SwiGLUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (relative_pe): AlibiPositionEmbeddingLayer()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=84992, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "model_path = \"inceptionai/jais-family-590m-chat\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", trust_remote_code=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd872e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "عاصمة دولة الإمارات العربية المتحدة، أبو ظبي، تعتبر واحدة من أكثر المدن جاذبية للسياح والزوار من جميع أنحاء العالم. تقع المدينة على ساحل الخليج العربي، وهي مركز هام للتجارة والأعمال والثقافة والتعليم. \n",
      "\n",
      "تم اختيار هذه المدينة بسبب موقعها الاستراتيجي، حيث تقع على خط الاستواء، مما يجعلها نقطة مثالية للأنشطة الخارجية مثل السباحة والغوص وركوب الأمواج. بالإضافة إلى ذلك، تعتبر أبو ظبي موطنًا لبعض أكبر الشركات العالمية في الشرق الأوسط، بما في ذلك مجموعة من الشركات متعددة الجنسيات الكبرى مثل سامسونج وهارفارد وتاتا موتورز.\n",
      "\n",
      "تعتبر أبو ظبي أيضًا مركزًا رئيسيًا للتعليم والبحث، مع العديد من الجامعات والمدارس الرائدة التي تقدم برامج تعليمية متنوعة. كما أنها موطن لعدد كبير من المعالم السياحية الشهيرة، بما في ذلك برج خليفة، أطول مبنى في العالم، وحديقة الشعب، التي تعتبر مكانًا مثاليًا لمشاهدة غروب الشمس والاستمتاع بالمناظر الطبيعية الخلابة.\n"
     ]
    }
   ],
   "source": [
    "prompt_ar = \"### Instruction:اسمك \\\"جيس\\\" وسميت على اسم جبل جيس اعلى جبل في الامارات. تم بنائك بواسطة Inception في الإمارات. أنت مساعد مفيد ومحترم وصادق. أجب دائمًا بأكبر قدر ممكن من المساعدة، مع الحفاظ على البقاء أمناً. أكمل المحادثة بين [|Human|] و[|AI|] :\\n### Input:[|Human|] {Question}\\n[|AI|]\\n### Response :\"\n",
    "device = \"mps\"\n",
    "def get_response(text, tokenizer=tokenizer, model=model):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    inputs = input_ids.to(device)\n",
    "    input_len = inputs.shape[-1]\n",
    "    generate_ids = model.generate(\n",
    "        inputs,\n",
    "        top_p=0.9,\n",
    "        temperature=0.3,\n",
    "        max_length=2048,\n",
    "        min_length=input_len + 4,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    response = tokenizer.batch_decode(\n",
    "        generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )[0]\n",
    "    response = response.split(\"### Response :\")[-1]\n",
    "    return response\n",
    "\n",
    "\n",
    "ques = \"ما هي عاصمة الامارات؟\"\n",
    "text = prompt_ar.format_map({'Question': ques})\n",
    "print(get_response(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e5973d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JAISLMHeadModel(\n",
       "  (transformer): JAISModel(\n",
       "    (wte): Embedding(84992, 1536)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-17): 18 x JAISBlock(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): JAISAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): JAISMLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_fc2): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): SwiGLUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (relative_pe): AlibiPositionEmbeddingLayer()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=84992, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad0189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu  is available\n",
      "before: trainable model parameters: 640555008\n",
      "all model parameters: 640555020\n",
      "percentage of trainable model parameters: 100.00%\n",
      "Replacing feedforward layers with RBF in block 0\n",
      "Replacing feedforward layers with RBF in block 1\n",
      "Replacing feedforward layers with RBF in block 2\n",
      "Replacing feedforward layers with RBF in block 3\n",
      "Replacing feedforward layers with RBF in block 4\n",
      "Replacing feedforward layers with RBF in block 5\n",
      "Replacing feedforward layers with RBF in block 6\n",
      "Replacing feedforward layers with RBF in block 7\n",
      "Replacing feedforward layers with RBF in block 8\n",
      "Replacing feedforward layers with RBF in block 9\n",
      "Replacing feedforward layers with RBF in block 10\n",
      "Replacing feedforward layers with RBF in block 11\n",
      "Replacing feedforward layers with RBF in block 12\n",
      "Replacing feedforward layers with RBF in block 13\n",
      "Replacing feedforward layers with RBF in block 14\n",
      "Replacing feedforward layers with RBF in block 15\n",
      "Replacing feedforward layers with RBF in block 16\n",
      "Replacing feedforward layers with RBF in block 17\n",
      "\n",
      "\n",
      "after: trainable model parameters: 301332588\n",
      "all model parameters: 301332600\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/omaratef/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from add_rbf_to_model import replace_ffn_with_rbf_jais\n",
    "from main import print_number_of_trainable_model_parameters\n",
    "print(\"before:\" , print_number_of_trainable_model_parameters(model))\n",
    "\n",
    "replace_ffn_with_rbf_jais(model, 2)\n",
    "print(\"\\n\")\n",
    "print(\"after:\" , print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9201fde",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m ques \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mما هي عاصمة الامارات؟\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m text \u001b[38;5;241m=\u001b[39m prompt_ar\u001b[38;5;241m.\u001b[39mformat_map({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m'\u001b[39m: ques})\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mget_response\u001b[0;34m(text, tokenizer, model)\u001b[0m\n\u001b[1;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m input_len \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m generate_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m     18\u001b[0m     generate_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Response :\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.9/site-packages/transformers/generation/utils.py:1525\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1518\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1519\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1520\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1521\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1522\u001b[0m     )\n\u001b[1;32m   1524\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1542\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1543\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1548\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1549\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.9/site-packages/transformers/generation/utils.py:2622\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2619\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2622\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2630\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/inceptionai/jais-family-590m-chat/90ac4769212b4964c6e81e183140224628228365/modeling_jais.py:1194\u001b[0m, in \u001b[0;36mJAISLMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1194\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/inceptionai/jais-family-590m-chat/90ac4769212b4964c6e81e183140224628228365/modeling_jais.py:922\u001b[0m, in \u001b[0;36mJAISModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;66;03m# Since attention_mask is 1.0 for positions we want to attend and 0.0 for\u001b[39;00m\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# masked positions, this operation will create a tensor which is 0.0 for\u001b[39;00m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;66;03m# positions we want to attend and the dtype's smallest value for masked positions.\u001b[39;00m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;66;03m# Since we are adding it to the raw scores before the softmax, this is\u001b[39;00m\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# effectively the same as removing these entirely.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)  \u001b[38;5;66;03m# fp16 compatibility\u001b[39;00m\n\u001b[0;32m--> 922\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mfinfo(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmin\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39madd_cross_attention \u001b[38;5;129;01mand\u001b[39;00m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py:966\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_VariableFunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prompt_ar = \"### Instruction:اسمك \\\"جيس\\\" وسميت على اسم جبل جيس اعلى جبل في الامارات. تم بنائك بواسطة Inception في الإمارات. أنت مساعد مفيد ومحترم وصادق. أجب دائمًا بأكبر قدر ممكن من المساعدة، مع الحفاظ على البقاء أمناً. أكمل المحادثة بين [|Human|] و[|AI|] :\\n### Input:[|Human|] {Question}\\n[|AI|]\\n### Response :\"\n",
    "device = \"mps\"\n",
    "model.to(\"mps\")\n",
    "def get_response(text, tokenizer=tokenizer, model=model):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "    inputs = input_ids.to(device)\n",
    "    input_len = inputs.shape[-1]\n",
    "    generate_ids = model.generate(\n",
    "        inputs,\n",
    "        top_p=0.9,\n",
    "        temperature=0.3,\n",
    "        max_length=2048,\n",
    "        min_length=input_len + 4,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    response = tokenizer.batch_decode(\n",
    "        generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )[0]\n",
    "    response = response.split(\"### Response :\")[-1]\n",
    "    return response\n",
    "\n",
    "\n",
    "ques = \"ما هي عاصمة الامارات؟\"\n",
    "text = prompt_ar.format_map({'Question': ques})\n",
    "print(get_response(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cbb8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "692b9d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removed shared tensor {'lm_head.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"./modified_rbf_model\")\n",
    "config.save_pretrained(\"./modified_rbf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65fe3f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omaratef/miniconda/envs/pytorch/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at ./modified_rbf_model were not used when initializing JAISLMHeadModel: ['transformer.h.0.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.0.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.0.mlp.c_fc.rbf_layer.weights', 'transformer.h.0.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.0.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.0.mlp.c_fc2.rbf_layer.weights', 'transformer.h.0.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.0.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.0.mlp.c_proj.rbf_layer.weights', 'transformer.h.1.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.1.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.1.mlp.c_fc.rbf_layer.weights', 'transformer.h.1.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.1.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.1.mlp.c_fc2.rbf_layer.weights', 'transformer.h.1.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.1.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.1.mlp.c_proj.rbf_layer.weights', 'transformer.h.10.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.10.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.10.mlp.c_fc.rbf_layer.weights', 'transformer.h.10.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.10.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.10.mlp.c_fc2.rbf_layer.weights', 'transformer.h.10.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.10.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.10.mlp.c_proj.rbf_layer.weights', 'transformer.h.11.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.11.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.11.mlp.c_fc.rbf_layer.weights', 'transformer.h.11.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.11.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.11.mlp.c_fc2.rbf_layer.weights', 'transformer.h.11.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.11.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.11.mlp.c_proj.rbf_layer.weights', 'transformer.h.12.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.12.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.12.mlp.c_fc.rbf_layer.weights', 'transformer.h.12.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.12.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.12.mlp.c_fc2.rbf_layer.weights', 'transformer.h.12.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.12.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.12.mlp.c_proj.rbf_layer.weights', 'transformer.h.13.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.13.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.13.mlp.c_fc.rbf_layer.weights', 'transformer.h.13.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.13.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.13.mlp.c_fc2.rbf_layer.weights', 'transformer.h.13.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.13.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.13.mlp.c_proj.rbf_layer.weights', 'transformer.h.14.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.14.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.14.mlp.c_fc.rbf_layer.weights', 'transformer.h.14.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.14.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.14.mlp.c_fc2.rbf_layer.weights', 'transformer.h.14.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.14.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.14.mlp.c_proj.rbf_layer.weights', 'transformer.h.15.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.15.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.15.mlp.c_fc.rbf_layer.weights', 'transformer.h.15.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.15.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.15.mlp.c_fc2.rbf_layer.weights', 'transformer.h.15.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.15.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.15.mlp.c_proj.rbf_layer.weights', 'transformer.h.16.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.16.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.16.mlp.c_fc.rbf_layer.weights', 'transformer.h.16.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.16.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.16.mlp.c_fc2.rbf_layer.weights', 'transformer.h.16.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.16.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.16.mlp.c_proj.rbf_layer.weights', 'transformer.h.17.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.17.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.17.mlp.c_fc.rbf_layer.weights', 'transformer.h.17.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.17.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.17.mlp.c_fc2.rbf_layer.weights', 'transformer.h.17.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.17.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.17.mlp.c_proj.rbf_layer.weights', 'transformer.h.2.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.2.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.2.mlp.c_fc.rbf_layer.weights', 'transformer.h.2.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.2.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.2.mlp.c_fc2.rbf_layer.weights', 'transformer.h.2.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.2.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.2.mlp.c_proj.rbf_layer.weights', 'transformer.h.3.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.3.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.3.mlp.c_fc.rbf_layer.weights', 'transformer.h.3.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.3.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.3.mlp.c_fc2.rbf_layer.weights', 'transformer.h.3.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.3.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.3.mlp.c_proj.rbf_layer.weights', 'transformer.h.4.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.4.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.4.mlp.c_fc.rbf_layer.weights', 'transformer.h.4.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.4.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.4.mlp.c_fc2.rbf_layer.weights', 'transformer.h.4.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.4.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.4.mlp.c_proj.rbf_layer.weights', 'transformer.h.5.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.5.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.5.mlp.c_fc.rbf_layer.weights', 'transformer.h.5.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.5.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.5.mlp.c_fc2.rbf_layer.weights', 'transformer.h.5.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.5.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.5.mlp.c_proj.rbf_layer.weights', 'transformer.h.6.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.6.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.6.mlp.c_fc.rbf_layer.weights', 'transformer.h.6.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.6.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.6.mlp.c_fc2.rbf_layer.weights', 'transformer.h.6.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.6.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.6.mlp.c_proj.rbf_layer.weights', 'transformer.h.7.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.7.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.7.mlp.c_fc.rbf_layer.weights', 'transformer.h.7.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.7.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.7.mlp.c_fc2.rbf_layer.weights', 'transformer.h.7.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.7.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.7.mlp.c_proj.rbf_layer.weights', 'transformer.h.8.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.8.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.8.mlp.c_fc.rbf_layer.weights', 'transformer.h.8.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.8.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.8.mlp.c_fc2.rbf_layer.weights', 'transformer.h.8.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.8.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.8.mlp.c_proj.rbf_layer.weights', 'transformer.h.9.mlp.c_fc.rbf_layer.kernels_centers', 'transformer.h.9.mlp.c_fc.rbf_layer.log_shapes', 'transformer.h.9.mlp.c_fc.rbf_layer.weights', 'transformer.h.9.mlp.c_fc2.rbf_layer.kernels_centers', 'transformer.h.9.mlp.c_fc2.rbf_layer.log_shapes', 'transformer.h.9.mlp.c_fc2.rbf_layer.weights', 'transformer.h.9.mlp.c_proj.rbf_layer.kernels_centers', 'transformer.h.9.mlp.c_proj.rbf_layer.log_shapes', 'transformer.h.9.mlp.c_proj.rbf_layer.weights']\n",
      "- This IS expected if you are initializing JAISLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing JAISLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of JAISLMHeadModel were not initialized from the model checkpoint at ./modified_rbf_model and are newly initialized: ['transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc2.bias', 'transformer.h.0.mlp.c_fc2.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc2.bias', 'transformer.h.1.mlp.c_fc2.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_fc2.bias', 'transformer.h.10.mlp.c_fc2.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.11.mlp.c_fc2.bias', 'transformer.h.11.mlp.c_fc2.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.12.mlp.c_fc.bias', 'transformer.h.12.mlp.c_fc.weight', 'transformer.h.12.mlp.c_fc2.bias', 'transformer.h.12.mlp.c_fc2.weight', 'transformer.h.12.mlp.c_proj.bias', 'transformer.h.12.mlp.c_proj.weight', 'transformer.h.13.mlp.c_fc.bias', 'transformer.h.13.mlp.c_fc.weight', 'transformer.h.13.mlp.c_fc2.bias', 'transformer.h.13.mlp.c_fc2.weight', 'transformer.h.13.mlp.c_proj.bias', 'transformer.h.13.mlp.c_proj.weight', 'transformer.h.14.mlp.c_fc.bias', 'transformer.h.14.mlp.c_fc.weight', 'transformer.h.14.mlp.c_fc2.bias', 'transformer.h.14.mlp.c_fc2.weight', 'transformer.h.14.mlp.c_proj.bias', 'transformer.h.14.mlp.c_proj.weight', 'transformer.h.15.mlp.c_fc.bias', 'transformer.h.15.mlp.c_fc.weight', 'transformer.h.15.mlp.c_fc2.bias', 'transformer.h.15.mlp.c_fc2.weight', 'transformer.h.15.mlp.c_proj.bias', 'transformer.h.15.mlp.c_proj.weight', 'transformer.h.16.mlp.c_fc.bias', 'transformer.h.16.mlp.c_fc.weight', 'transformer.h.16.mlp.c_fc2.bias', 'transformer.h.16.mlp.c_fc2.weight', 'transformer.h.16.mlp.c_proj.bias', 'transformer.h.16.mlp.c_proj.weight', 'transformer.h.17.mlp.c_fc.bias', 'transformer.h.17.mlp.c_fc.weight', 'transformer.h.17.mlp.c_fc2.bias', 'transformer.h.17.mlp.c_fc2.weight', 'transformer.h.17.mlp.c_proj.bias', 'transformer.h.17.mlp.c_proj.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.2.mlp.c_fc2.bias', 'transformer.h.2.mlp.c_fc2.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc2.bias', 'transformer.h.3.mlp.c_fc2.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.4.mlp.c_fc2.bias', 'transformer.h.4.mlp.c_fc2.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.5.mlp.c_fc2.bias', 'transformer.h.5.mlp.c_fc2.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc2.bias', 'transformer.h.6.mlp.c_fc2.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.7.mlp.c_fc2.bias', 'transformer.h.7.mlp.c_fc2.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.8.mlp.c_fc2.bias', 'transformer.h.8.mlp.c_fc2.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.9.mlp.c_fc2.bias', 'transformer.h.9.mlp.c_fc2.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.9.mlp.c_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded modified model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JAISLMHeadModel(\n",
       "  (transformer): JAISModel(\n",
       "    (wte): Embedding(84992, 1536)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-17): 18 x JAISBlock(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): JAISAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): JAISMLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_fc2): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): SwiGLUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (relative_pe): AlibiPositionEmbeddingLayer()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=84992, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "# Load the modified model from the saved directory\n",
    "config = AutoConfig.from_pretrained(\"./modified_rbf_model\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./modified_rbf_model\", config=config, trust_remote_code=True)\n",
    "\n",
    "print(\"Loaded modified model:\")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad51f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu  is available\n",
      "after: trainable model parameters: 640555008\n",
      "all model parameters: 640555020\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/omaratef/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from main import print_number_of_trainable_model_parameters\n",
    "\n",
    "print(\"after:\" , print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d3ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
